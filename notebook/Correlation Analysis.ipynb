{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3facd26",
   "metadata": {},
   "source": [
    "**Correlation between news and stock movement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d27a17c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  #importing neccessary libraries for the operation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc58915c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded news_data.csv from file.\n",
      "Data loaded successfully from AAPL\n",
      "Data loaded successfully from AMZN\n",
      "Data loaded successfully from GOOG\n",
      "Data loaded successfully from META\n",
      "Data loaded successfully from MSFT\n",
      "Data loaded successfully from NVDA\n",
      "Data loaded successfully from TSLA\n",
      "Stock data loaded (or dummy data generated).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_Signal</th>\n",
       "      <th>MACD_Hist</th>\n",
       "      <th>Daily_Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-12-12</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.098943</td>\n",
       "      <td>469033600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-12-15</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.093781</td>\n",
       "      <td>175884800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.052171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.086898</td>\n",
       "      <td>105728000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.073398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-12-17</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.089049</td>\n",
       "      <td>86441600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-12-18</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.091630</td>\n",
       "      <td>73449600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10993</th>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.800003</td>\n",
       "      <td>217.130005</td>\n",
       "      <td>218.539993</td>\n",
       "      <td>218.287323</td>\n",
       "      <td>61777600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.228500</td>\n",
       "      <td>48.687742</td>\n",
       "      <td>4.662717</td>\n",
       "      <td>6.678882</td>\n",
       "      <td>-2.016164</td>\n",
       "      <td>-0.028754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10994</th>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>218.929993</td>\n",
       "      <td>220.850006</td>\n",
       "      <td>214.619995</td>\n",
       "      <td>217.490005</td>\n",
       "      <td>217.238556</td>\n",
       "      <td>51391200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.440500</td>\n",
       "      <td>47.386437</td>\n",
       "      <td>3.748082</td>\n",
       "      <td>6.092722</td>\n",
       "      <td>-2.344640</td>\n",
       "      <td>-0.004805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>218.699997</td>\n",
       "      <td>219.490005</td>\n",
       "      <td>216.009995</td>\n",
       "      <td>217.960007</td>\n",
       "      <td>217.708008</td>\n",
       "      <td>41601300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.633500</td>\n",
       "      <td>48.055700</td>\n",
       "      <td>3.026267</td>\n",
       "      <td>5.479431</td>\n",
       "      <td>-2.453164</td>\n",
       "      <td>0.002161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>216.960007</td>\n",
       "      <td>219.300003</td>\n",
       "      <td>215.750000</td>\n",
       "      <td>218.240005</td>\n",
       "      <td>217.987686</td>\n",
       "      <td>36311800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.014500</td>\n",
       "      <td>48.476184</td>\n",
       "      <td>2.448591</td>\n",
       "      <td>4.873263</td>\n",
       "      <td>-2.424672</td>\n",
       "      <td>0.001285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>2024-07-30</td>\n",
       "      <td>219.190002</td>\n",
       "      <td>220.330002</td>\n",
       "      <td>216.119995</td>\n",
       "      <td>218.800003</td>\n",
       "      <td>218.547043</td>\n",
       "      <td>41643800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.117001</td>\n",
       "      <td>49.359115</td>\n",
       "      <td>2.012764</td>\n",
       "      <td>4.301163</td>\n",
       "      <td>-2.288399</td>\n",
       "      <td>0.002566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10998 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date        Open        High         Low       Close   Adj Close  \\\n",
       "0      1980-12-12    0.128348    0.128906    0.128348    0.128348    0.098943   \n",
       "1      1980-12-15    0.122210    0.122210    0.121652    0.121652    0.093781   \n",
       "2      1980-12-16    0.113281    0.113281    0.112723    0.112723    0.086898   \n",
       "3      1980-12-17    0.115513    0.116071    0.115513    0.115513    0.089049   \n",
       "4      1980-12-18    0.118862    0.119420    0.118862    0.118862    0.091630   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "10993  2024-07-24  224.000000  224.800003  217.130005  218.539993  218.287323   \n",
       "10994  2024-07-25  218.929993  220.850006  214.619995  217.490005  217.238556   \n",
       "10995  2024-07-26  218.699997  219.490005  216.009995  217.960007  217.708008   \n",
       "10996  2024-07-29  216.960007  219.300003  215.750000  218.240005  217.987686   \n",
       "10997  2024-07-30  219.190002  220.330002  216.119995  218.800003  218.547043   \n",
       "\n",
       "          Volume  Dividends  Stock Splits      SMA_20     RSI_14      MACD  \\\n",
       "0      469033600        0.0           0.0         NaN        NaN       NaN   \n",
       "1      175884800        0.0           0.0         NaN        NaN       NaN   \n",
       "2      105728000        0.0           0.0         NaN        NaN       NaN   \n",
       "3       86441600        0.0           0.0         NaN        NaN       NaN   \n",
       "4       73449600        0.0           0.0         NaN        NaN       NaN   \n",
       "...          ...        ...           ...         ...        ...       ...   \n",
       "10993   61777600        0.0           0.0  224.228500  48.687742  4.662717   \n",
       "10994   51391200        0.0           0.0  224.440500  47.386437  3.748082   \n",
       "10995   41601300        0.0           0.0  224.633500  48.055700  3.026267   \n",
       "10996   36311800        0.0           0.0  225.014500  48.476184  2.448591   \n",
       "10997   41643800        0.0           0.0  225.117001  49.359115  2.012764   \n",
       "\n",
       "       MACD_Signal  MACD_Hist  Daily_Return  \n",
       "0              NaN        NaN           NaN  \n",
       "1              NaN        NaN     -0.052171  \n",
       "2              NaN        NaN     -0.073398  \n",
       "3              NaN        NaN      0.024751  \n",
       "4              NaN        NaN      0.028992  \n",
       "...            ...        ...           ...  \n",
       "10993     6.678882  -2.016164     -0.028754  \n",
       "10994     6.092722  -2.344640     -0.004805  \n",
       "10995     5.479431  -2.453164      0.002161  \n",
       "10996     4.873263  -2.424672      0.001285  \n",
       "10997     4.301163  -2.288399      0.002566  \n",
       "\n",
       "[10998 rows x 15 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    # Attempt to load your actual news data file\n",
    "    news_df = pd.read_csv(r'C:\\Users\\hp\\Nova-Solutions-News-Sentiment-Price-Forecasts\\notebook\\data\\Processed_data\\news_data_processed.csv')\n",
    "    print(\"Loaded news_data.csv from file.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"news_data.csv not found. Using dummy news data for demonstration.\")\n",
    "\n",
    "# --- Stock Data (Dictionary of DataFrames) ---\n",
    "#Stock data source path\n",
    "\n",
    "AAPL_path=r'C:\\Users\\hp\\Nova-Solutions-News-Sentiment-Price-Forecasts\\notebook\\data\\Processed_data\\AAPL_stock_data.csv'\n",
    "AMZN_path=r'C:\\Users\\hp\\Nova-Solutions-News-Sentiment-Price-Forecasts\\notebook\\data\\Processed_data\\AMZN_stock_data.csv'\n",
    "GOOG_path=r'C:\\Users\\hp\\Nova-Solutions-News-Sentiment-Price-Forecasts\\notebook\\data\\Processed_data\\GOOG_stock_data.csv'\n",
    "META_path=r'C:\\Users\\hp\\Nova-Solutions-News-Sentiment-Price-Forecasts\\notebook\\data\\Processed_data\\META_stock_data.csv'\n",
    "MSFT_path=r'C:\\Users\\hp\\Nova-Solutions-News-Sentiment-Price-Forecasts\\notebook\\data\\Processed_data\\MSFT_stock_data.csv'\n",
    "NVDA_path=r'C:\\Users\\hp\\Nova-Solutions-News-Sentiment-Price-Forecasts\\notebook\\data\\Processed_data\\NVDA_stock_data.csv'\n",
    "TSLA_path=r'C:\\Users\\hp\\Nova-Solutions-News-Sentiment-Price-Forecasts\\notebook\\data\\Processed_data\\TSLA_stock_data.csv'\n",
    "\n",
    "#Loading Stock data from csv\n",
    "try:\n",
    "    AAPL_df = pd.read_csv(AAPL_path)\n",
    "    print(f\"Data loaded successfully from AAPL\")\n",
    "    AMZN_df = pd.read_csv(AMZN_path)\n",
    "    print(f\"Data loaded successfully from AMZN\")\n",
    "    GOOG_df = pd.read_csv(GOOG_path)\n",
    "    print(f\"Data loaded successfully from GOOG\")\n",
    "    META_df = pd.read_csv(META_path)\n",
    "    print(f\"Data loaded successfully from META\")\n",
    "    MSFT_df = pd.read_csv(MSFT_path)\n",
    "    print(f\"Data loaded successfully from MSFT\")\n",
    "    NVDA_df = pd.read_csv(NVDA_path)\n",
    "    print(f\"Data loaded successfully from NVDA\")\n",
    "    TSLA_df = pd.read_csv(TSLA_path)\n",
    "    print(f\"Data loaded successfully from TSLA\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file AAPL_path was not found. Please check the path.\")\n",
    "    print(f\"Error: The file AMZN_path was not found. Please check the path.\")\n",
    "    print(f\"Error: The file GOOG_path was not found. Please check the path.\")\n",
    "    print(f\"Error: The file META_path was not found. Please check the path.\")\n",
    "    print(f\"Error: The file MSFT_path was not found. Please check the path.\")\n",
    "    print(f\"Error: The file NVDA_path was not found. Please check the path.\")\n",
    "    print(f\"Error: The file TSLA_path was not found. Please check the path.\")\n",
    "print(\"Stock data loaded\")\n",
    "\n",
    "stock_data = {\n",
    "     \"AAPL\": AAPL_df,\n",
    "     \"AMZN\": AMZN_df,\n",
    "     \"MSFT\":MSFT_df,\n",
    "     \"TSLA\":TSLA_df,\n",
    "     \"META\":META_df,\n",
    "     \"NVDA\":NVDA_df,\n",
    "     \"GOOG\":GOOG_df,\n",
    "                   }\n",
    "\n",
    "stock_data[\"AAPL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d938c7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 2: Daily Returns & Sentiment Aggregation Starting ---\n",
      "  AAPL: 'Daily_Return' found. Renaming to 'daily_return' for consistency.\n",
      "  AMZN: 'Daily_Return' found. Renaming to 'daily_return' for consistency.\n",
      "  MSFT: 'Daily_Return' found. Renaming to 'daily_return' for consistency.\n",
      "  TSLA: 'Daily_Return' found. Renaming to 'daily_return' for consistency.\n",
      "  META: 'Daily_Return' found. Renaming to 'daily_return' for consistency.\n",
      "  NVDA: 'Daily_Return' found. Renaming to 'daily_return' for consistency.\n",
      "  GOOG: 'Daily_Return' found. Renaming to 'daily_return' for consistency.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- Phase 2: Daily Returns & Sentiment Aggregation Starting ---\")\n",
    "\n",
    "columns_to_check_for_nan = ['Daily_Return', 'SMA_20', 'RSI_14', 'MACD', 'MACD_Signal', 'MACD_Hist']\n",
    "\n",
    "all_daily_returns = []\n",
    "processed_individual_stock_dfs = {}\n",
    "\n",
    "# Iterate through each stock's DataFrame in the 'stock_data' dictionary (from pre-processing)\n",
    "for ticker, df in stock_data.items():\n",
    "\n",
    "    if 'Daily_Return' in df.columns:\n",
    "        df.rename(columns={'Daily_Return': 'daily_return'}, inplace=True)\n",
    "        print(f\"  {ticker}: 'Daily_Return' found. Renaming to 'daily_return' for consistency.\")\n",
    "    elif 'daily_return' in df.columns:\n",
    "        print(f\"  {ticker}: 'daily_return' found. Using existing column.\")\n",
    "    else: # Fallback: calculate if neither 'Daily_Return' nor 'daily_return' exists\n",
    "        print(f\"  {ticker}: Neither 'Daily_Return' nor 'daily_return' found. Calculating daily percentage change from 'Close'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6bee6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GOOG: Renamed 'Date' column to 'date'.\n"
     ]
    }
   ],
   "source": [
    "    if isinstance(df.index, pd.DatetimeIndex) or df.index.name in ['Date', 'date']:\n",
    "        df.reset_index(inplace=True)\n",
    "        # After reset_index, the former index becomes a column. Its name depends on the original index name.\n",
    "        # Let's ensure it's named 'date' (lowercase)\n",
    "        if df.columns[0] == 'Date': # If original index name was 'Date'\n",
    "            df.rename(columns={'Date': 'date'}, inplace=True)\n",
    "            print(f\"  {ticker}: 'Date' from index reset to column 'date'.\")\n",
    "        elif df.columns[0] == 'date': # If original index name was 'date'\n",
    "            print(f\"  {ticker}: 'date' from index reset to column 'date'.\")\n",
    "        else: # If index had no name, it might be an unnamed column (0)\n",
    "            df.rename(columns={df.columns[0]: 'date'}, inplace=True)\n",
    "            print(f\"  {ticker}: Unnamed index reset to column 'date'.\")\n",
    "    elif 'Date' in df.columns and 'date' not in df.columns:\n",
    "        df.rename(columns={'Date': 'date'}, inplace=True)\n",
    "        print(f\"  {ticker}: Renamed 'Date' column to 'date'.\")\n",
    "    elif 'date' not in df.columns: # If no date column or index found\n",
    "        print(f\"  Warning: {ticker} has no discernible 'date' column or date in index. Skipping this ticker.\")\n",
    "    \n",
    "      \n",
    "    # Ensure 'date' column is in datetime format for robust operations\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    # Convert to date objects for consistency with news_df if news_df uses date objects\n",
    "    df['date'] = df['date'].dt.date\n",
    "\n",
    "    # Ensure data is sorted by the standardized 'date' column\n",
    "    df.sort_values(by='date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8bc6ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in ['SMA_20', 'RSI_14', 'MACD', 'MACD_Signal', 'MACD_Hist']:\n",
    "        if col_name not in df.columns:\n",
    "            print(f\"  Warning: Expected column '{col_name}' not found for {ticker}. Check your input data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e745cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ticker'] = ticker\n",
    "if 'date' in df.columns and 'daily_return' in df.columns:\n",
    "        all_daily_returns.append(df[['date', 'ticker', 'daily_return']])\n",
    "        processed_individual_stock_dfs[ticker] = df # Store the fully processed DataFrame\n",
    "else:\n",
    "        print(f\"  Warning: Skipping {ticker} from aggregation due to missing 'date' or 'daily_return' column after processing steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0cc2c52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Daily Stock Movement (Portfolio Level, first 5 rows):\n",
      "         date  average_daily_return_decimal  average_daily_return_percent\n",
      "0  2004-08-19                           NaN                           NaN\n",
      "1  2004-08-20                      0.079430                      7.942989\n",
      "2  2004-08-23                      0.010064                      1.006362\n",
      "3  2004-08-24                     -0.041408                     -4.140766\n",
      "4  2004-08-25                      0.010775                      1.077510\n",
      "Shape of average_daily_stock_movement: (5020, 3)\n"
     ]
    }
   ],
   "source": [
    "if all_daily_returns:\n",
    "    combined_returns_df = pd.concat(all_daily_returns)\n",
    "\n",
    "    # Calculate the average daily return across all tickers for each specific day.\n",
    "    average_daily_stock_movement = combined_returns_df.groupby('date')['daily_return'].mean().reset_index()\n",
    "    average_daily_stock_movement['average_daily_return_percent'] = average_daily_stock_movement['daily_return'] * 100\n",
    "    average_daily_stock_movement.rename(columns={'daily_return': 'average_daily_return_decimal'}, inplace=True)\n",
    "    print(\"\\nAverage Daily Stock Movement (Portfolio Level, first 5 rows):\")\n",
    "    print(average_daily_stock_movement.head())\n",
    "    print(f\"Shape of average_daily_stock_movement: {average_daily_stock_movement.shape}\")\n",
    "else:\n",
    "    print(\"\\nNo valid stock data found after processing. Cannot calculate average daily stock movement.\")\n",
    "    average_daily_stock_movement = pd.DataFrame() # Create an empty DataFrame to prevent downstream errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6be26663",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Date' in news_df.columns and 'date' not in news_df.columns:\n",
    "    news_df.rename(columns={'Date': 'date'}, inplace=True)\n",
    "    print(\"News_df: Renamed 'Date' column to 'date'.\")\n",
    "# Also convert to datetime and then date object if it's not already\n",
    "if 'date' in news_df.columns:\n",
    "    news_df['date'] = pd.to_datetime(news_df['date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0b8aee2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16190091/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-05</td>\n",
       "      <td>A</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16170189/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>A</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16103463/7...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>A</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095921/4...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>A</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095304/b...</td>\n",
       "      <td>Vick Meyer</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>A</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407323</th>\n",
       "      <td>1413844</td>\n",
       "      <td>Top Narrow Based Indexes For August 29</td>\n",
       "      <td>https://www.benzinga.com/news/11/08/1888782/to...</td>\n",
       "      <td>Monica Gerson</td>\n",
       "      <td>2011-08-29</td>\n",
       "      <td>ZX</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407324</th>\n",
       "      <td>1413845</td>\n",
       "      <td>Recap: Wednesday's Top Percentage Gainers and ...</td>\n",
       "      <td>https://www.benzinga.com/news/earnings/11/06/1...</td>\n",
       "      <td>Benjamin Lee</td>\n",
       "      <td>2011-06-22</td>\n",
       "      <td>ZX</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407325</th>\n",
       "      <td>1413846</td>\n",
       "      <td>UPDATE: Oppenheimer Color on China Zenix Auto ...</td>\n",
       "      <td>https://www.benzinga.com/analyst-ratings/analy...</td>\n",
       "      <td>BenzingaStaffL</td>\n",
       "      <td>2011-06-21</td>\n",
       "      <td>ZX</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407326</th>\n",
       "      <td>1413847</td>\n",
       "      <td>Oppenheimer Initiates China Zenix At Outperfor...</td>\n",
       "      <td>https://www.benzinga.com/analyst-ratings/price...</td>\n",
       "      <td>Joe Young</td>\n",
       "      <td>2011-06-21</td>\n",
       "      <td>ZX</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407327</th>\n",
       "      <td>1413848</td>\n",
       "      <td>China Zenix Auto International Opens For Tradi...</td>\n",
       "      <td>https://www.benzinga.com/news/ipos/11/05/10789...</td>\n",
       "      <td>Allie Wickman</td>\n",
       "      <td>2011-05-12</td>\n",
       "      <td>ZX</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1407328 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                                           headline  \\\n",
       "0                 0            Stocks That Hit 52-Week Highs On Friday   \n",
       "1                 1         Stocks That Hit 52-Week Highs On Wednesday   \n",
       "2                 2                      71 Biggest Movers From Friday   \n",
       "3                 3       46 Stocks Moving In Friday's Mid-Day Session   \n",
       "4                 4  B of A Securities Maintains Neutral on Agilent...   \n",
       "...             ...                                                ...   \n",
       "1407323     1413844             Top Narrow Based Indexes For August 29   \n",
       "1407324     1413845  Recap: Wednesday's Top Percentage Gainers and ...   \n",
       "1407325     1413846  UPDATE: Oppenheimer Color on China Zenix Auto ...   \n",
       "1407326     1413847  Oppenheimer Initiates China Zenix At Outperfor...   \n",
       "1407327     1413848  China Zenix Auto International Opens For Tradi...   \n",
       "\n",
       "                                                       url          publisher  \\\n",
       "0        https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
       "1        https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
       "2        https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
       "3        https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
       "4        https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
       "...                                                    ...                ...   \n",
       "1407323  https://www.benzinga.com/news/11/08/1888782/to...      Monica Gerson   \n",
       "1407324  https://www.benzinga.com/news/earnings/11/06/1...       Benjamin Lee   \n",
       "1407325  https://www.benzinga.com/analyst-ratings/analy...     BenzingaStaffL   \n",
       "1407326  https://www.benzinga.com/analyst-ratings/price...          Joe Young   \n",
       "1407327  https://www.benzinga.com/news/ipos/11/05/10789...      Allie Wickman   \n",
       "\n",
       "               date stock  Sentiment  \n",
       "0        2020-06-05     A       0.00  \n",
       "1        2020-06-03     A       0.00  \n",
       "2        2020-05-26     A       0.00  \n",
       "3        2020-05-22     A       0.00  \n",
       "4        2020-05-22     A       0.00  \n",
       "...             ...   ...        ...  \n",
       "1407323  2011-08-29    ZX       0.15  \n",
       "1407324  2011-06-22    ZX       0.15  \n",
       "1407325  2011-06-21    ZX       0.00  \n",
       "1407326  2011-06-21    ZX       0.00  \n",
       "1407327  2011-05-12    ZX       0.00  \n",
       "\n",
       "[1407328 rows x 7 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "96123c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregated Daily General Market Sentiment (first 5 rows):\n",
      "         date  average_daily_general_sentiment\n",
      "0  2009-02-14                         0.000000\n",
      "1  2009-04-27                         0.000000\n",
      "2  2009-04-29                         0.000000\n",
      "3  2009-05-22                         0.000000\n",
      "4  2009-05-27                         0.234091\n",
      "Shape of daily_general_sentiment: (3955, 2)\n",
      "\n",
      "--- Phase 2: Daily Returns & Sentiment Aggregation Complete ---\n"
     ]
    }
   ],
   "source": [
    "if 'date' in news_df.columns and 'Sentiment' in news_df.columns:\n",
    "    daily_general_sentiment = news_df.groupby('date')['Sentiment'].mean().reset_index()\n",
    "    daily_general_sentiment.rename(columns={'Sentiment': 'average_daily_general_sentiment'}, inplace=True)\n",
    "    print(\"\\nAggregated Daily General Market Sentiment (first 5 rows):\")\n",
    "    print(daily_general_sentiment.head())\n",
    "    print(f\"Shape of daily_general_sentiment: {daily_general_sentiment.shape}\")\n",
    "else:\n",
    "    print(\"\\nError: News_df is missing 'date' or 'sentiment_score' column. Cannot aggregate sentiment.\")\n",
    "    daily_general_sentiment = pd.DataFrame() # Create an empty DataFrame to prevent downstream errors\n",
    "\n",
    "print(\"\\n--- Phase 2: Daily Returns & Sentiment Aggregation Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0b367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
